{"data":{"wordpressPost":{"title":"How to DDoS yourself with analytics ‚Äì‚Äì a war story","content":"<p><em>&#8220;Application error is preventing tutors from ending their shifts </em> üòû&#8221;</p>\n<p>&#8230;</p>\n<p><em>&#8220;Tutors in sessions are noticing that it says they are offline!&#8221;</em></p>\n<p>&#8230;</p>\n<p>It was 1:28am Monday night, two days before Thanksgiving. Literally the lowest hour of the lowest week for traffic all year. Our servers were melting.</p>\n<p>I saw the message by accident. Good thing I was up üòÖ</p>\n<img class=\"alignnone size-full wp-image-7939\" src=\"https://swizec.com/blog/wp-content/uploads/2017/11/Screen-Shot-2017-11-28-at-23.44.45.png\" width=\"713\" height=\"439\" srcset=\"https://swizec.com/blog/wp-content/uploads/2017/11/Screen-Shot-2017-11-28-at-23.44.45.png 713w, https://swizec.com/blog/wp-content/uploads/2017/11/Screen-Shot-2017-11-28-at-23.44.45-300x185.png 300w\" sizes=\"(max-width: 713px) 100vw, 713px\" />\n<p>*&#8221;@sharon looks like everything is down and our servers are on fire. I restarted the server, can you see if that helped?&#8221;</p>\n<p>Average API response time ‚Üí 30 seconds. Usually, it&#8217;s 0.3 seconds.</p>\n<p>Restarting helped. Restarting a Rails server always helps. I went to bed.</p>\n<p>At 9am, our servers were melting.</p>\n<p>I restarted.</p>\n<p>At 10:30am, our servers were melting.</p>\n<p>We suspected analytics, deployed a quick patch to disable the workers, restarted servers, and got to work.</p>\n<img src=\"https://media.giphy.com/media/l2QEgWxqxI2WJCXpC/giphy.gif\" />\n<h2>The perfect storm</h2>\n<blockquote><p>\nSaving blobs of JSON into an array is hard</p>\n<p>~Swizec\n</p></blockquote>\n<blockquote><p>\nLoL it&#8217;s just an array with some objects how hard can it be</p>\n<p>~The Internet\n</p></blockquote>\n<p>So how does a server melt on the lowest week of traffic for the entire year? And how does it start melting again just a few hours later even though it was fine for many months before that?</p>\n<p>The problem with exponential problems is that you don&#8217;t see them coming until it&#8217;s too late.</p>\n<p>API response times grow millisecond by millisecond, getting ever so much larger. ‚ÄúNothing alarming, normal fluctuation,‚Äù you say to yourself.</p>\n<p>Then BAM! Response times are 30 seconds and Heroku force timeouts all your requests. Now you&#8217;re in trouble.</p>\n<p>That&#8217;s why it happened so much faster the 2nd time. And even faster the 3rd time.</p>\n<p>But <em>why</em>?</p>\n<p>Because saving a bunch of JSON blobs reliably is hard. The &#8220;reliably&#8221; part is what gets you.</p>\n<p>How do you make sure clients can send analytics events and ensure none of them get dropped?</p>\n<p>If the request fails, you store the event and try again later.</p>\n<p>How do you avoid sending too many requests since failing requests are the likeliest cause of most errors?</p>\n<p>You batch multiple events into the same request.</p>\n<p>Congratulations, you just created an API that can lead to your clients <a href=\"https://en.wikipedia.org/wiki/Denial-of-service_attack\">DDoSing</a> your own server.</p>\n<p>üòÅ</p>\n<p>A DDoS is a distributed denial of service attack, by the way. It happens when so many clients send your server so many requests that it crumples under the pressure.</p>\n<p>Similar in principle to the Reddit or HackerNews <a href=\"https://en.wikipedia.org/wiki/Slashdot_effect\">hug of death</a>. That&#8217;s when a link gets so popular that the flood of traffic melts servers.</p>\n<h2>Why storing, retrying, and batching requests spells trouble</h2>\n<p>You see, there is nothing wrong with storing failed requests and retrying them. Or with batching multiple small requests into one being one. It&#8217;s the smart thing to do even.</p>\n<p>It&#8217;s when your backend has bugs that it leads to trouble.</p>\n<p>What happens if you send a batch of 10 events and the server fails to process 1 of them? Say, because an error happens when attaching additional properties?</p>\n<p>The server says <em>&#8220;Hey, I couldn&#8217;t process this batch.‚Äù</em></p>\n<p>So you say, <em>&#8220;Oh, it failed. I&#8217;ll try again later.‚Äù</em></p>\n<p>Later comes. You have some new events, too. So you send a batch of 20 events.</p>\n<p>The same event fails. Next time, you send 30.</p>\n<p>See what that leads to yet?</p>\n<p>That&#8217;s right. Eventually, you&#8217;re sending so many events at the same time that the server has trouble processing them all within a single request. This begins to impact other clients&#8217; requests.</p>\n<p>The server is busy processing. Other clients say <em>&#8220;Yo, here&#8217;s my stuff‚Äù,</em> and get denied.</p>\n<p>Failures happen with no rhyme or reason. It depends completely on who is currently using the service and whether their client has a large backlog of events to send.</p>\n<p>The problem festers and grows.</p>\n<p>The more clients experience an issue, the more clients have large backlogs, the more issues occur.</p>\n<img src=\"https://media.giphy.com/media/NQTttAGByybAI/giphy.gif\" />\n<p>Eventually, your server melts, and nobody can&#8217;t do nothing no more.</p>\n<h2>The fix?</h2>\n<p>A preprocessing queue.</p>\n<p>When a client sends a request with some events, just store the raw payload somewhere and deal with it later.</p>\n<p>Requests almost always succeed, so events don&#8217;t pile up on clients. Saving the raw payload is also fast, which makes overall performance faster for the clients, too.</p>\n<p>Processing offline also gives you more time. Instead of having to do everything in 30 seconds, you can spend many minutes on a big request if you have to.</p>\n<p>Plus, you can mark specific events as failing, but still process everything else.</p>\n<h2>Lessons learned ‚Üí</h2>\n<p>Saving arrays of JSON blobs is hard.</p>\n"},"site":{"siteMetadata":{"title":"Swizec Blog","subtitle":"Fetch Data From Local WP Install"}}},"pageContext":{"id":"459b3a3d-9893-5459-9254-c8b72ea7c7f1"}}