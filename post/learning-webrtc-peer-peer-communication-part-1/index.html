<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/swizecblog/component---src-components-post-js.345c7c4f16662f410581.css">@import url(https://fonts.googleapis.com/css?family=Lora);
html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;font-family:Lora,serif}body{background-color:#f6f6f6;margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{-webkit-text-decoration-skip:objects;background-color:transparent}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:Lora,serif;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{box-sizing:border-box;font:112.5%/1.45em georgia,serif;overflow-y:scroll}*,:after,:before{box-sizing:inherit}body{-moz-font-feature-settings:"kern","liga","clig","calt";-ms-font-feature-settings:"kern","liga","clig","calt";-webkit-font-feature-settings:"kern","liga","clig","calt";color:rgba(0,0,0,.8);font-family:Lora,serif;font-feature-settings:"kern","liga","clig","calt";font-kerning:normal;font-weight:400;word-wrap:break-word}img{margin:0 0 1.45rem;max-width:100%;padding:0}h1{font-size:2.25rem}h1,h2{color:inherit;font-family:Lora,serif;font-weight:700;line-height:1.1;margin:0 0 1.45rem;padding:0;text-rendering:optimizeLegibility}h2{font-size:1.62671rem}h3{font-size:1.38316rem}h3,h4{color:inherit;font-family:Lora,serif;font-weight:700;line-height:1.1;margin:0 0 1.45rem;padding:0;text-rendering:optimizeLegibility}h4{font-size:1rem}h5{font-size:.85028rem}h5,h6{color:inherit;font-family:Lora,serif;font-weight:700;line-height:1.1;margin:0 0 1.45rem;padding:0;text-rendering:optimizeLegibility}h6{font-size:.78405rem}hgroup{margin:0 0 1.45rem;padding:0}ol,ul{list-style-image:none;list-style-position:outside;margin:0 0 1.45rem 1.45rem;padding:0}dd,dl,figure,p{margin:0 0 1.45rem;padding:0}pre{background:rgba(0,0,0,.04);border-radius:3px;font-size:.85rem;line-height:1.42;margin:0 0 1.45rem;overflow:auto;padding:1.45rem;word-wrap:normal}table{border-collapse:collapse;font-size:1rem;line-height:1.45rem;width:100%}fieldset,table{margin:0 0 1.45rem;padding:0}blockquote{margin:0 1.45rem 1.45rem;padding:0}form,iframe,noscript{margin:0 0 1.45rem;padding:0}hr{background:rgba(0,0,0,.2);border:none;height:1px;margin:0 0 calc(1.45rem - 1px);padding:0}address{margin:0 0 1.45rem;padding:0}b,dt,strong,th{font-weight:700}li{margin-bottom:.725rem}ol li,ul li{padding-left:0}li>ol,li>ul{margin-bottom:.725rem;margin-left:1.45rem;margin-top:.725rem}blockquote :last-child,li :last-child,p :last-child{margin-bottom:0}li>p{margin-bottom:.725rem}code,kbd,samp{font-size:.85rem;line-height:1.45rem}abbr,abbr[title],acronym{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help}abbr[title]{text-decoration:none}td,th,thead{text-align:left}td,th{-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";border-bottom:1px solid rgba(0,0,0,.12);font-feature-settings:"tnum";padding:.725rem .96667rem calc(.725rem - 1px)}td:first-child,th:first-child{padding-left:0}td:last-child,th:last-child{padding-right:0}code,tt{background-color:rgba(0,0,0,.04);border-radius:3px;font-family:Lora,serif;padding:.2em 0}pre code{background:none;line-height:1.42}code:after,code:before,tt:after,tt:before{content:" ";letter-spacing:-.2em}pre code:after,pre code:before,pre tt:after,pre tt:before{content:""}@media only screen and (max-width:480px){html{font-size:100%}}

/*# sourceMappingURL=component---src-components-post-js.345c7c4f16662f410581.css.map*/</style><style data-styled-components="cEsjyT hklXLQ gpHXOM cTUdjA">
/* sc-component-id: sc-bdVaJa */
.cEsjyT{margin:3rem auto;max-width:960px;padding:1.25rem 1rem;} .cEsjyT ul{margin:0 0 0px 0;list-style:none;float:right;}
/* sc-component-id: sc-bwzfXH */
.cTUdjA{-webkit-text-decoration:none;text-decoration:none;text-align:right;margin:0 .5rem 0 .5rem;padding:10px;color:#7c51a1;} .cTUdjA:hover{color:#fff;background-color:#7c51a1;}
/* sc-component-id: sc-htpNat */
.gpHXOM{-webkit-text-decoration:none;text-decoration:none;color:black;} .gpHXOM:hover{-webkit-text-decoration:underline;text-decoration:underline;color:#7c51a1;} .gpHXOM h3{display:inline;font-size:30px;}
/* sc-component-id: sc-bxivhb */
.hklXLQ{margin:0 3rem 4.5rem;}</style><title data-react-helmet="true">Swizec Blog</title><meta data-react-helmet="true" name="description" content="Sample"/><meta data-react-helmet="true" name="keywords" content="sample, something"/><link as="script" rel="preload" href="/swizecblog/component---src-components-post-js-dbedf083f25f7ad1f3b1.js"/><link as="script" rel="preload" href="/swizecblog/0-f215691c134019ee6fa5.js"/><link as="script" rel="preload" href="/swizecblog/app-49ff0b4ea28eff25fc3b.js"/><link as="script" rel="preload" href="/swizecblog/webpack-runtime-b34af8fd410bb07c9828.js"/><link rel="preload" href="/swizecblog/static/d/824/path---post-learning-webrtc-peer-peer-communication-part-1-441-88d-DlQi6CAG5hqqOKe2ppusompZY.json" as="fetch" crossOrigin="use-credentials"/></head><body><div id="___gatsby"><div><div class="sc-bdVaJa cEsjyT"><div class="sc-bxivhb hklXLQ"><a class="sc-htpNat gpHXOM" href="/swizecblog/"><h3>Swizec Teller</h3></a><ul><a class="sc-bwzfXH cTUdjA" href="/swizecblog/Business/">Business</a><a class="sc-bwzfXH cTUdjA" href="/swizecblog/Personal/">Personal</a><a class="sc-bwzfXH cTUdjA" href="/swizecblog/Technical/">Technical</a><a class="sc-bwzfXH cTUdjA" href="/swizecblog/Thoughts/">Thoughts</a></ul></div><h1>Learning WebRTC peer-to-peer communication, part 1</h1><div><p><iframe width="580" height="326" src="https://www.youtube.com/embed/pjoem5laCYQ?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></p>
<p>Remember <a href="https://github.com/Swizec/blockchain-redux">blockchain-redux</a>? Yeah, I&#8217;m still working on it. Last time, we got it to <a href="https://swizec.com/blog/blockchain-redux-shares-blocks-between-clients-real-time/swizec/8320">share blocks between clients in real-time</a>.</p>
<p>But that still used Firebase as the communication channel. Our blockchain isn&#8217;t really distributed. ‚òπÔ∏è</p>
<p>I have to fix that before my talk at <a href="https://www.wearedevelopers.com/congress/">WeAreDevelopers Congress</a> in Vienna. Otherwise, what&#8217;s the point?</p>
<p>WebRTC can do that for us. Get browsers to talk to each other without any servers at all.</p>
<p>I built <a href="https://swizec.github.io/webrtc-sample/">a demo app</a> that uses <code>RTCPeerConnection</code> to build a peer-to-peer connection with itself. You can see the <a href="https://github.com/Swizec/webrtc-sample/blob/master/src/WebRTCPeerConnection.js">code on GitHub</a> or keep reading.</p>
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">Got same page WebRTC working o/</p>
<p>Now how do I peer-to-peer ü§î <a href="https://t.co/kHTPrmpJp5">pic.twitter.com/kHTPrmpJp5</a></p>
<p>&mdash; Swizec (@Swizec) <a href="https://twitter.com/Swizec/status/993269639235842051?ref_src=twsrc%5Etfw">May 6, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Since iOS 11, WebRTC now works in all browsers people use. You can use it for real! üëçüèº</p>
<p><a href="https://swizec.github.io/webrtc-sample/">Try my demo here</a>. I&#8217;d embed an iframe, but browser security rules say no.</p>
<p>WebRTC offers 3 APIs:</p>
<ul>
<li>get video and audio from devices <a href="https://www.html5rocks.com/en/tutorials/webrtc/basics/#toc-mediastream">(<code>MediaStream</code>)</a></li>
<li>establish peer-to-peer connections <a href="https://www.html5rocks.com/en/tutorials/webrtc/basics/#toc-rtcpeerconnection">(<code>RTCPeerConnection</code>)</a></li>
<li>send arbitrary data <a href="https://www.html5rocks.com/en/tutorials/webrtc/basics/#toc-rtcdatachannel">(<code>RTCDataChannel</code>)</a></li>
</ul>
<p>In this article, we&#8217;ll use 2 of them. Media and peer connection.</p>
<h2>RTCPeerConnection connects clients without servers</h2>
<div id="attachment_8358" style="width: 1639px" class="wp-caption alignnone"><img class="alignnone size-full wp-image-8358" src="https://swizec.com/blog/wp-content/uploads/2018/05/RTCPeerConnection-process-sketch.png" alt="RTCPeerConnection process sketch" width="1629" height="1989" srcset="https://swizec.com/blog/wp-content/uploads/2018/05/RTCPeerConnection-process-sketch.png 1629w, https://swizec.com/blog/wp-content/uploads/2018/05/RTCPeerConnection-process-sketch-246x300.png 246w, https://swizec.com/blog/wp-content/uploads/2018/05/RTCPeerConnection-process-sketch-768x938.png 768w, https://swizec.com/blog/wp-content/uploads/2018/05/RTCPeerConnection-process-sketch-839x1024.png 839w" sizes="(max-width: 1629px) 100vw, 1629px" /><p class="wp-caption-text">RTCPeerConnection process sketch</p></div>
<p>You establish a connection between 2 clients on the same page like this üëá</p>
<ol>
<li>Instantiate two <code>RTCPeerConnection</code> objects</li>
<li>Add each other as ICE candidates</li>
<li><code>createOffer</code> on the 1st object</li>
<li>set local/remote &#8220;description&#8221; on both</li>
<li><code>createAnswer</code> on the 2nd object</li>
<li>set remote/local &#8220;description&#8221; on both</li>
<li>Enjoy your direct communication</li>
</ol>
<p>Here&#8217;s how that goes <a href="https://github.com/Swizec/webrtc-sample/blob/master/src/WebRTCPeerConnection.js">in code</a>.</p>
<p>We start with a React component that renders 2 videos and 3 buttons. It has a bunch of default state that we&#8217;ll use to drive everything.</p>
<pre lang="javascript">
class WebRTCPeerConnection extends React.Component {
    state = {
        startDisabled: false,
        callDisabled: true,
        hangUpDisabled: true,
        servers: null,
        pc1: null,
        pc2: null,
        localStream: null
    };

    localVideoRef = React.createRef();
    remoteVideoRef = React.createRef();

    start = () => {
        // start media devices
    };

    call = () => {
        // initiate a call
    };

    hangUp = () => {
        // hang up connection
    };

    render() {
        const { startDisabled, callDisabled, hangUpDisabled } = this.state;

        return (
            <div>
                <video
                    ref={this.localVideoRef}
                    autoPlay
                    muted
                    style={{ width: "240px", height: "180px" }}
                />
                <video
                    ref={this.remoteVideoRef}
                    autoPlay
                    style={{ width: "240px", height: "180px" }}
                />

                <div>
                    <button onClick={this.start} disabled={startDisabled}>
                        Start
                    </button>
                    <button onClick={this.call} disabled={callDisabled}>
                        Call
                    </button>
                    <button onClick={this.hangUp} disabled={hangUpDisabled}>
                        Hang Up
                    </button>
                </div>
            </div>
        );
    }
}
</pre>
<p>We have 3 booleans that enable/disable our buttons, <code>null</code> peer connections <code>pc1</code> and <code>pc2</code>, I don&#8217;t know what <code>servers</code> are for, and we render videos and buttons.</p>
<h2>Step 1 ‚Üí start</h2>
<p>When you click the <code>Start</code> button, we ask for audio/video permissions and start a <code>localStream</code>.</p>
<pre lang="javascript">
    start = () => {
        this.setState({
            startDisabled: true
        });
        navigator.mediaDevices
            .getUserMedia({
                audio: true,
                video: true
            })
            .then(this.gotStream)
            .catch(e => alert("getUserMedia() error:" + e.name));
    };
    
    gotStream = stream => {
        this.localVideoRef.current.srcObject = stream;
        this.setState({
            callDisabled: false,
            localStream: stream
        });
    };
</pre>
<p>Disable the start button with <code>this.setState</code>, get your media with <code>navigator.getUserMedia</code>. If you give permission, we start streaming in the <code>localVideo</code> element and add it to state.</p>
<h2>Step 2 ‚Üí Call</h2>
<p>You can now press the <code>Call</code> button. That starts two peer connections, <code>pc1</code> and <code>pc2</code>, and goes through the dance to get them talking to each other.</p>
<ol>
<li><code>call</code> initiates the offer</li>
<li><code>onCreateOfferSuccess</code> updates both pcs and initiates the answer</li>
<li><code>onCreateAnswerSuccess</code> finishes the handshake</li>
<li><code>gotRemoteStream</code> wakes up and sets the second video</li>
</ol>
<pre lang="javascript">
    call = () => {
        this.setState({
            callDisabled: true,
            hangUpDisabled: false
        });
        let { localStream } = this.state;

        let servers = null,
            pc1 = new RTCPeerConnection(servers),
            pc2 = new RTCPeerConnection(servers);

        pc1.onicecandidate = e => this.onIceCandidate(pc1, e);
        pc1.oniceconnectionstatechange = e => this.onIceStateChange(pc1, e);

        pc2.onicecandidate = e => this.onIceCandidate(pc2, e);
        pc2.oniceconnectionstatechange = e => this.onIceStateChange(pc2, e);
        pc2.ontrack = this.gotRemoteStream;

        localStream
            .getTracks()
            .forEach(track => pc1.addTrack(track, localStream));

        pc1
            .createOffer({
                offerToReceiveAudio: 1,
                offerToReceiveVideo: 1
            })
            .then(this.onCreateOfferSuccess, error =>
                console.error(
                    "Failed to create session description",
                    error.toString()
                )
            );

        this.setState({
            servers,
            pc1,
            pc2,
            localStream
        });
    };
</pre>
<p>This code is mostly boilerplate.</p>
<p>We enable and disable the appropriate buttons, get <code>localStream</code> from state, and instantiate <code>servers</code>, <code>pc1</code>, and <code>pc2</code>.</p>
<p>Both <code>pc*</code> objects get a bunch of event listeners. <code>onIceCandidate</code> will connect them to each other, <code>onIceStateChange</code> just prints debugging info, and <code>gotRemoteStream</code> will add it to the right <code>&lt;video&gt;</code> element.</p>
<p>Then we take all tracks from <code>localStream</code> (audio and video) and add them to the first client. After that <code>pc1</code> creates an offer to receive its video and audio.</p>
<p>When all that&#8217;s done, we update component state.</p>
<h3>onCreateOfferSuccess</h3>
<p>After <code>pc1</code> successfully creates an offer to be received, we update local and remote descriptions in our clients. I&#8217;m not sure what these &#8220;descriptions&#8221; are, but it&#8217;s where the important stuff happens.</p>
<pre lang="javascript">
    onCreateOfferSuccess = desc => {
        let { pc1, pc2 } = this.state;

        pc1
            .setLocalDescription(desc)
            .then(
                () =>
                    console.log("pc1 setLocalDescription complete createOffer"),
                error =>
                    console.error(
                        "pc1 Failed to set session description in createOffer",
                        error.toString()
                    )
            );

        pc2.setRemoteDescription(desc).then(
            () => {
                console.log("pc2 setRemoteDescription complete createOffer");
                pc2
                    .createAnswer()
                    .then(this.onCreateAnswerSuccess, error =>
                        console.error(
                            "pc2 Failed to set session description in createAnswer",
                            error.toString()
                        )
                    );
            },
            error =>
                console.error(
                    "pc2 Failed to set session description in createOffer",
                    error.toString()
                )
        );
    };
</pre>
<p><code>pc1</code> updates its local description, and <code>pc2</code> updates its remote description. <code>pc2</code> also creates an answer, which I think is akin to saying <em>&#8220;Okay, I accepted your offer, let&#8217;s do this&#8221;</em>.</p>
<h3>onCreateAnswerSuccess</h3>
<p>When <code>pc2</code> successfully creates an answer, we do another round of description setting. This time in reverse order.</p>
<pre lang="javascript">
    onCreateAnswerSuccess = desc => {
        let { pc1, pc2 } = this.state;

        pc1
            .setRemoteDescription(desc)
            .then(
                () =>
                    console.log(
                        "pc1 setRemoteDescription complete createAnswer"
                    ),
                error =>
                    console.error(
                        "pc1 Failed to set session description in onCreateAnswer",
                        error.toString()
                    )
            );

        pc2
            .setLocalDescription(desc)
            .then(
                () =>
                    console.log(
                        "pc2 setLocalDescription complete createAnswer"
                    ),
                error =>
                    console.error(
                        "pc2 Failed to set session description in onCreateAnswer",
                        error.toString()
                    )
            );
    };
</pre>
<p><code>pc1</code> sets its remote description and <code>pc2</code> sets its local description. I think this acknowledges that, from <code>pc1</code>&#8216;s perspective, it is local to itself and <code>pc2</code> is remote, and vice-versa for <code>pc2</code>.</p>
<p>¬Ø&#92;_(„ÉÑ)_/¬Ø</p>
<p>At this point, we have two video streams talking to each other on the same page.</p>
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">Got same page WebRTC working o/</p>
<p>Now how do I peer-to-peer ü§î <a href="https://t.co/kHTPrmpJp5">pic.twitter.com/kHTPrmpJp5</a></p>
<p>&mdash; Swizec (@Swizec) <a href="https://twitter.com/Swizec/status/993269639235842051?ref_src=twsrc%5Etfw">May 6, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h3>onIceCandidate</h3>
<p>At some point during all this, both <code>pc*</code>s say that they&#8217;ve got an ICE candidate. Don&#8217;t know when exactly that happens, but it gives us a chance to tell each client who they&#8217;re talking to.</p>
<pre lang="javascript">
    onIceCandidate = (pc, event) => {
        let { pc1, pc2 } = this.state;

        let otherPc = pc === pc1 ? pc2 : pc1;

        otherPc
            .addIceCandidate(event.candidate)
            .then(
                () => console.log("addIceCandidate success"),
                error =>
                    console.error(
                        "failed to add ICE Candidate",
                        error.toString()
                    )
            );
    };
</pre>
<p>We guess the other client and add it as a candidate. If we had more than 2, this could get tricky.</p>
<h2>Step 3: HangUp</h2>
<p>Hanging up is easy. You close both clients.</p>
<pre lang="javascript">
    hangUp = () => {
        let { pc1, pc2 } = this.state;

        pc1.close();
        pc2.close();

        this.setState({
            pc1: null,
            pc2: null,
            hangUpDisabled: true,
            callDisabled: false
        });
    };
</pre>
<h2>The tricky part</h2>
<p>This works great as a tech demo. And that&#8217;s when your dreams are shattered.</p>
<p>The first part of your connection, where two clients find each other, is called signaling. The WebRTC spec doesn&#8217;t say anything about signaling.</p>
<p>It&#8217;s easy in a single page, two client demo. Both clients are right there, in memory. And there&#8217;s only two clients to boot.</p>
<p>But in the real world, you want those clients to run in different browsers, on different machines, far apart in the world. How do you make them find each other? What if there&#8217;s thousands?</p>
<p>Well, you need some sort of communication channel that knows where all the clients are and can say <em>&#8220;Yo, connect here. You, over there!&#8221;</em>. A central server of some sort‚Ä¶</p>
<p>That won&#8217;t do for a distributed decentralized blockchain ‚òπÔ∏è</p>
<p>Next step: Serverless WebRTC signaling. Stay tuned.</p>
<p>&lt;strong<em>This is a Livecoding Recap ‚Äì an almost-weekly post about interesting things discovered while livecoding. Usually shorter than 500 words. Often with pictures. Livecoding happens almost <strong>every Sunday at 2pm PDT</strong> on multiple channels. You should subscribe to <a href="https://www.youtube.com/TheSwizec">My Youtube</a> channel to catch me live.</em></strong></p>
</div></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.page={"componentChunkName":"component---src-components-post-js","jsonName":"post-learning-webrtc-peer-peer-communication-part-1-441","path":"/post/learning-webrtc-peer-peer-communication-part-1/"};window.dataPath="824/path---post-learning-webrtc-peer-peer-communication-part-1-441-88d-DlQi6CAG5hqqOKe2ppusompZY";/*]]>*/</script><script src="/swizecblog/webpack-runtime-b34af8fd410bb07c9828.js" async=""></script><script src="/swizecblog/app-49ff0b4ea28eff25fc3b.js" async=""></script><script src="/swizecblog/0-f215691c134019ee6fa5.js" async=""></script><script src="/swizecblog/component---src-components-post-js-dbedf083f25f7ad1f3b1.js" async=""></script></body></html>